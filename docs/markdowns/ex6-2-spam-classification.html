
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>ex6 2 Spam classification · GitBook</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-disqus/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-back-to-top-button/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="ex7-k-means-clustering-and-pca.html" />
    
    
    <link rel="prev" href="ex6-1-support-vector-machines.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    Machine Learning 정리
            
                </a>
            

            
        </li>
    

    
        
        <li class="divider"></li>
        
        
    
        <li class="chapter " data-level="2.1" data-path="1-introduction.html">
            
                <a href="1-introduction.html">
            
                    
                    1 Introduction
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.1.1" data-path="1.1-introduction.html">
            
                <a href="1.1-introduction.html">
            
                    
                    1.1 Introduction.md
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.1.2" data-path="1.2-linear-regression-with-one-variable.html">
            
                <a href="1.2-linear-regression-with-one-variable.html">
            
                    
                    1.2 Linear regression with one variable.md
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.1.3" data-path="1.3-linear-algebra-review.html">
            
                <a href="1.3-linear-algebra-review.html">
            
                    
                    1.3 Linear algebra review.md
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="2.2" data-path="2-linear-regression-with-multiple-variables.html">
            
                <a href="2-linear-regression-with-multiple-variables.html">
            
                    
                    2 Linear regression with multiple variables.md
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.2.1" data-path="2.1-multivariate-linear-regression.html">
            
                <a href="2.1-multivariate-linear-regression.html">
            
                    
                    2.1 Multivariate linear regression.md
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.2.2" data-path="2.2-computing-parameters-analytically.html">
            
                <a href="2.2-computing-parameters-analytically.html">
            
                    
                    2.2 Computing parameters analytically.md
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="2.3" data-path="3-logistic-regression-regularization.html">
            
                <a href="3-logistic-regression-regularization.html">
            
                    
                    3 Logistic regression regularization.md
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.3.1" data-path="3.1-logistic-regression.html">
            
                <a href="3.1-logistic-regression.html">
            
                    
                    3.1 Logistic regression.md
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.3.2" data-path="3.2-regularization-and-overfitting-problem.html">
            
                <a href="3.2-regularization-and-overfitting-problem.html">
            
                    
                    3.2 Regularization and overfitting problem.md
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="2.4" data-path="4-neural-networks.html">
            
                <a href="4-neural-networks.html">
            
                    
                    4 Neural networks.md
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.5" data-path="5-neural-networks-learning.html">
            
                <a href="5-neural-networks-learning.html">
            
                    
                    5 Neural networks learning.md
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.6" data-path="6-advice-for-applying-machine-learning.html">
            
                <a href="6-advice-for-applying-machine-learning.html">
            
                    
                    6 Advice for applying machine learning.md
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.7" data-path="7-machine-learning-system-design.html">
            
                <a href="7-machine-learning-system-design.html">
            
                    
                    7 Machine learning system design.md
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.8" data-path="8-support-vector-machines.html">
            
                <a href="8-support-vector-machines.html">
            
                    
                    8 Support vector machines.md
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.9" data-path="9-unsupervised-learning--dimensionality-reduction.html">
            
                <a href="9-unsupervised-learning--dimensionality-reduction.html">
            
                    
                    9 Unsupervised learning  dimensionality reduction.md
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.10" data-path="10-dimensionality-reduction.html">
            
                <a href="10-dimensionality-reduction.html">
            
                    
                    10 Dimensionality reduction.md
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.11" data-path="11-anormaly-detection.html">
            
                <a href="11-anormaly-detection.html">
            
                    
                    11 Anormaly detection.md
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.12" data-path="12-recommander-systems.html">
            
                <a href="12-recommander-systems.html">
            
                    
                    12 Recommander systems.md
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.13" data-path="13-large-scale-machine-learning.html">
            
                <a href="13-large-scale-machine-learning.html">
            
                    
                    13 Large scale machine learning.md
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.14" data-path="14-application-example-photo-ocr.html">
            
                <a href="14-application-example-photo-ocr.html">
            
                    
                    14 Application example photo ocr.md
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.15" data-path="15-vectorized-implementations-in-octave.html">
            
                <a href="15-vectorized-implementations-in-octave.html">
            
                    
                    15 Vectorized implementations in octave.md
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">Exercises</li>
        
        
    
        <li class="chapter " data-level="3.1" data-path="ex2.1-logistic-regression.html">
            
                <a href="ex2.1-logistic-regression.html">
            
                    
                    ex2.1 Logistic regression
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.2" data-path="ex2.2-regularized-logistic-regression.html">
            
                <a href="ex2.2-regularized-logistic-regression.html">
            
                    
                    ex2.2 Regularized logistic regression
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.3" data-path="ex3-1-multi-class-classification.html">
            
                <a href="ex3-1-multi-class-classification.html">
            
                    
                    ex3 1 Multi class classification
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.4" data-path="ex3-2-neural-networks.html">
            
                <a href="ex3-2-neural-networks.html">
            
                    
                    ex3 2 Neural networks
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.5" data-path="ex4-1-neural-networks.html">
            
                <a href="ex4-1-neural-networks.html">
            
                    
                    ex4 1 Neural networks
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.6" data-path="ex4-2-backpropagation.html">
            
                <a href="ex4-2-backpropagation.html">
            
                    
                    ex4 2 Backpropagation
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.7" data-path="ex5-regularized-LR-bias-variance.html">
            
                <a href="ex5-regularized-LR-bias-variance.html">
            
                    
                    ex5 Regularized Linear Regression and Bias-Variance
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.8" data-path="ex6-1-support-vector-machines.html">
            
                <a href="ex6-1-support-vector-machines.html">
            
                    
                    ex6 1 Support vector machines
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="3.9" data-path="ex6-2-spam-classification.html">
            
                <a href="ex6-2-spam-classification.html">
            
                    
                    ex6 2 Spam classification
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.10" data-path="ex7-k-means-clustering-and-pca.html">
            
                <a href="ex7-k-means-clustering-and-pca.html">
            
                    
                    ex7 K-means clustering and pca
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.11" data-path="ex8-recommander-system.html">
            
                <a href="ex8-recommander-system.html">
            
                    
                    ex8 Recommander system
            
                </a>
            

            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            Published with GitBook
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >ex6 2 Spam classification</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ]
    }
    });
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<script> MathJax.Hub.Queue(["Typeset",MathJax.Hub]); </script>




<h1 id="ex6-2-spam-classification">ex6-2 Spam classification</h1>
<hr>
<!-- toc -->
<ul>
<li><a href="#part-1-email-preprocessing">Part 1: Email Preprocessing</a></li>
<li><a href="#part-2-feature-extraction">Part 2: Feature Extraction</a></li>
<li><a href="#part-3-train-linear-svm-for-spam-classification">Part 3: Train Linear SVM for Spam Classification</a></li>
<li><a href="#part-4-test-spam-classification">Part 4: Test Spam Classification</a></li>
<li><a href="#part-5-top-predictors-of-spam">Part 5: Top Predictors of Spam</a></li>
<li><a href="#part-6-try-your-own-emails">Part 6: Try Your Own Emails</a></li>
</ul>
<!-- tocstop -->
<h2 id="part-1-email-preprocessing">Part 1: Email Preprocessing</h2>
<hr>
<ol>
<li>normialize : &#xAC01; &#xB2E8;&#xC5B4;&#xB4E4;&#xC744; &#xC9D1;&#xACC4;&#xD558;&#xAE30; &#xC27D;&#xAC8C; &#xBCC0;&#xACBD;, &#xBD88;&#xD544;&#xC694; charactor&#xC81C;&#xAC70;  </li>
<li>&#xAC01; &#xB2E8;&#xC5B4; mapping: email&#xC744; vocabList &#xC5D0; &#xC788;&#xB294; index&#xB85C; &#xBCC0;&#xACBD;&#xD558;&#xAE30; -&gt; email&#xC774; &#xBC88;&#xD638;&#xAC00; &#xB098;&#xC5F4;&#xB41C; &#xBCA1;&#xD130;&#xAC00;&#xB428;.    </li>
</ol>
<p>&#xACB0;&#xACFC;&#xC801;&#xC73C;&#xB85C; &#xC774;&#xBA54;&#xC77C;&#xC774; mapping&#xB41C; &#xC22B;&#xC790;&#xAC00; &#xB4E4;&#xC5B4;&#xC788;&#xB294; &#xBCA1;&#xD130; word_indices&#xB85C; &#xBCC0;&#xACBD;&#xB428;.  </p>
<p>caller  </p>
<pre><code class="lang-matlab"><span class="hljs-comment">% Extract Features  </span>
file_contents = readFile(<span class="hljs-string">&apos;emailSample1.txt&apos;</span>);  
word_indices  = processEmail(file_contents);
</code></pre>
<p>&#xAD6C;&#xD604;&#xB0B4;&#xC6A9;: 2(mapping)  </p>
<pre><code class="lang-matlab"><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">word_indices</span> = <span class="hljs-title">processEmail</span><span class="hljs-params">(email_contents)</span>  </span>
...(&#xC911;&#xB7B5;)  
<span class="hljs-keyword">while</span> ~<span class="hljs-built_in">isempty</span>(email_contents)  
    ...(&#xC911;&#xB7B5;)  
    <span class="hljs-keyword">for</span> <span class="hljs-built_in">i</span>=<span class="hljs-number">1</span>:<span class="hljs-built_in">size</span>(vocabList,<span class="hljs-number">1</span>)  
        <span class="hljs-keyword">if</span> strcmp(vocabList(<span class="hljs-built_in">i</span>), str)  
            word_indices = [word_indices ; i];  
        <span class="hljs-keyword">end</span>  
    <span class="hljs-keyword">end</span>  
<span class="hljs-keyword">end</span>
</code></pre>
<h2 id="part-2-feature-extraction">Part 2: Feature Extraction</h2>
<hr>
<p>mapping&#xB41C; email&#xC5D0;&#xC11C; feature vector x&#xB97C; &#xCD94;&#xCD9C;&#xD574;&#xC57C;&#xD55C;&#xB2E4;. &#xACB0;&#xACFC;&#xC801;&#xC73C;&#xB85C; &#xD558;&#xB098;&#xC758; email&#xC5D0;&#xC11C; &#xB2E4;&#xC74C;&#xACFC; &#xAC19;&#xC740; &#xD615;&#xD0DC;&#xC758; x&#xBCA1;&#xD130;&#xAC00; &#xCD94;&#xCD9C;&#xB420; &#xAC83;&#xC774;&#xB2E4;. (vocabList &#xAC2F;&#xC218;&#xAC00; 1899&#xAC1C;)    </p>
<p><script type="math/tex; ">  
x =   
\begin{bmatrix}  
0 \\  
\vdots \\  
1 \\  
0 \\  
\vdots \\  
0 \\  
1 \\  
\end{bmatrix}  
\in \mathbb{R}^{1899}  
</script>  </p>
<p>Caller    </p>
<pre><code class="lang-matlab"><span class="hljs-comment">% Extract Features  </span>
file_contents = readFile(<span class="hljs-string">&apos;emailSample1.txt&apos;</span>);  
word_indices  = processEmail(file_contents);  
features      = emailFeatures(word_indices);
</code></pre>
<pre><code class="lang-matlab"><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">x</span> = <span class="hljs-title">emailFeatures</span><span class="hljs-params">(word_indices)</span>  </span>
...(&#xC911;&#xB7B5;)  
<span class="hljs-keyword">for</span> <span class="hljs-built_in">i</span>=<span class="hljs-number">1</span>:<span class="hljs-built_in">size</span>(word_indices,<span class="hljs-number">1</span>)  
    x(word_indices) = <span class="hljs-number">1</span>;  
<span class="hljs-keyword">end</span>
</code></pre>
<h2 id="part-3-train-linear-svm-for-spam-classification">Part 3: Train Linear SVM for Spam Classification</h2>
<hr>
<p>spamTrain.mat&#xC740; &#xC6B0;&#xB9AC;&#xAC00; &#xD559;&#xC2B5;&#xD560; trainig examples &#xC774;&#xB2E4;.<br>spamTrain.mat &#xC5D0;&#xB294; &#xC704;&#xCC98;&#xB7FC; email&#xC744; feature vector x&#xB85C; mapping&#xD55C; 1899&#xD06C;&#xAE30;&#xC758; x&#xBCA1;&#xD130;&#xAC00; 4000&#xAC1C; &#xD3EC;&#xD568;&#xB418;&#xC5B4;&#xC788;&#xB2E4;.    </p>
<pre><code class="lang-matlab"><span class="hljs-comment">% Load the Spam Email dataset  </span>
<span class="hljs-comment">% You will have X, y in your environment  </span>
load(<span class="hljs-string">&apos;spamTrain.mat&apos;</span>);
</code></pre>
<p>load &#xD558;&#xBA74; feature &#xBCA1;&#xD130; X&#xC640; &#xADF8;&#xC5D0; &#xC0C1;&#xC751;&#xD558;&#xB294; &#xACB0;&#xACFC;&#xAC12; y&#xAC00; load &#xB41C;&#xB2E4;. y&#xB294; 4000&#xAC1C;&#xC758; &#xAC01; email&#xC774; spam&#xC778;&#xC9C0; &#xC544;&#xB2CC;&#xC9C0; 0 or 1&#xB85C; &#xB418;&#xC5B4;&#xC788;&#xB2E4;.<br>&#xB9CC;&#xC57D; &#xC720;&#xC0AC;&#xD55C; &#xD504;&#xB85C;&#xC81D;&#xD2B8;&#xB97C; &#xD558;&#xB824;&#xBA74; &#xC774;&#xB7F0; training data&#xB97C; &#xC0AC;&#xC804;&#xC5D0; &#xC218;&#xC9D1;&#xD574;&#xC57C;&#xD55C;&#xB2E4;.    </p>
<pre><code>        X               4000x1899                60768000  double    
        features        1899x1                      15192  double    
        y               4000x1                      32000  double
</code></pre><p>&#xADF8; &#xB4A4; &#xD574;&#xB2F9; &#xB370;&#xC774;&#xD130;&#xB97C; SVM&#xC73C;&#xB85C; train&#xC2DC;&#xD0A8;&#xB2E4;. (C=0.1)  </p>
<pre><code class="lang-matlab">C = <span class="hljs-number">0.1</span>;  
model = svmTrain(X, y, C, @linearKernel);
</code></pre>
<blockquote>
<p>&#xC774;&#xB807;&#xAC8C; &#xC0DD;&#xC131;&#xD55C; model&#xC744; &#xAC00;&#xC9C0;&#xACE0; &#xC55E;&#xC73C;&#xB85C; &#xBAA8;&#xB450; &#xC608;&#xCE21;&#xD560; &#xAC83;&#xC774;&#xB2E4;.    </p>
</blockquote>
<p>gaussianKernel &#xCEE4;&#xB110;&#xC744; &#xC0AC;&#xC6A9;&#xD55C;&#xB2E4;&#xBA74; &#xC544;&#xB798;&#xC640; &#xAC19;&#xC774; &#xBCC0;&#xACBD;  </p>
<pre><code class="lang-matlab">x1 = [<span class="hljs-number">1</span> <span class="hljs-number">2</span> <span class="hljs-number">1</span>]; x2 = [<span class="hljs-number">0</span> <span class="hljs-number">4</span> <span class="hljs-number">-1</span>]; sigma = <span class="hljs-number">2</span>;  
model= svmTrain(X, y, C, @(x1, x2) gaussianKernel(x1, x2, sigma));
</code></pre>
<p>(&#xCC38;&#xACE0;) model&#xC5D0; &#xC800;&#xC7A5;&#xB418;&#xC5B4;&#xC788;&#xB294; &#xAC12;&#xC740; &#xBB34;&#xC5C7;&#xC77C;&#xAE4C;?<br>who   </p>
<blockquote>
<p>model              1x1                   11801400  struct<br>model.<br>model.X               model.b               model.w<br>model.alphas          model.kernelFunction  model.y<br>model&#xC740; &#xC774;&#xB807;&#xAC8C; 6&#xAC1C;&#xC758; matrix&#xB85C; &#xC774;&#xB8E8;&#xC5B4;&#xC838; &#xC788;&#xC74C;.    </p>
</blockquote>
<p>&#xADF8; &#xB4A4;, predict&#xD55C;&#xB2E4;.<br>training sets  X&#xC5D0; &#xB300;&#xD55C; &#xACB0;&#xACFC;&#xB97C; &#xC608;&#xCE21;&#xD55C; &#xACB0;&#xACFC;&#xAC00; &#xC2E4;&#xC81C; y&#xC640; &#xC5BC;&#xB9C8;&#xB098; &#xAC00;&#xAE4C;&#xC6B4;&#xC9C0; &#xD655;&#xC778;&#xD558;&#xB294; &#xACFC;&#xC815;&#xC774;&#xB2E4;.    </p>
<pre><code class="lang-matlab">p = svmPredict(model, X);  
fprintf(<span class="hljs-string">&apos;Training Accuracy: %f\n&apos;</span>, mean(double(p == y)) * <span class="hljs-number">100</span>);
</code></pre>
<p>svmPredict() &#xC740; &#xAC01; &#xBAA8;&#xB378;&#xC5D0; &#xB9DE;&#xAC8C; &#xC608;&#xCE21;&#xD55C;&#xACB0;&#xACFC; p&#xB97C; return &#xD55C;&#xB2E4;.   </p>
<pre><code class="lang-matlab"><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">pred</span> = <span class="hljs-title">svmPredict</span><span class="hljs-params">(model, X)</span>  </span>
<span class="hljs-comment">%SVMPREDICT returns a vector of predictions using a trained SVM model  </span>
<span class="hljs-comment">%(svmTrain).   </span>
<span class="hljs-comment">%   pred = SVMPREDICT(model, X) returns a vector of predictions using a   </span>
<span class="hljs-comment">%   trained SVM model (svmTrain). X is a mxn matrix where there each   </span>
<span class="hljs-comment">%   example is a row. model is a svm model returned from svmTrain.  </span>
<span class="hljs-comment">%   predictions pred is a m x 1 column of predictions of {0, 1} values.  </span>
<span class="hljs-comment">%  </span>

<span class="hljs-comment">% Dataset   </span>
m = <span class="hljs-built_in">size</span>(X, <span class="hljs-number">1</span>);  
p = <span class="hljs-built_in">zeros</span>(m, <span class="hljs-number">1</span>);  
pred = <span class="hljs-built_in">zeros</span>(m, <span class="hljs-number">1</span>);  

<span class="hljs-keyword">if</span> strcmp(func2str(model.kernelFunction), <span class="hljs-string">&apos;linearKernel&apos;</span>)  
    <span class="hljs-comment">% We can use the weights and bias directly if working with the   </span>
    <span class="hljs-comment">% linear kernel  </span>
    p = X * model.w + model.b;  
<span class="hljs-keyword">elseif</span> strfind(func2str(model.kernelFunction), <span class="hljs-string">&apos;gaussianKernel&apos;</span>)  
    <span class="hljs-comment">% Vectorized RBF Kernel  </span>
    <span class="hljs-comment">% This is equivalent to computing the kernel on every pair of examples  </span>
    X1 = sum(X.^<span class="hljs-number">2</span>, <span class="hljs-number">2</span>);  
    X2 = sum(model.X.^<span class="hljs-number">2</span>, <span class="hljs-number">2</span>)&apos;;  
    K = <span class="hljs-built_in">bsxfun</span>(@plus, X1, <span class="hljs-built_in">bsxfun</span>(@plus, X2, - <span class="hljs-number">2</span> * X * model.X&apos;));  
    K = model.kernelFunction(<span class="hljs-number">1</span>, <span class="hljs-number">0</span>) .^ K;  
    K = <span class="hljs-built_in">bsxfun</span>(@times, model.y&apos;, K);  
    K = <span class="hljs-built_in">bsxfun</span>(@times, model.alphas&apos;, K);  
    p = sum(K, <span class="hljs-number">2</span>);  
<span class="hljs-keyword">else</span>  
    <span class="hljs-comment">% Other Non-linear kernel  </span>
    <span class="hljs-keyword">for</span> <span class="hljs-built_in">i</span> = <span class="hljs-number">1</span>:m  
        prediction = <span class="hljs-number">0</span>;  
        <span class="hljs-keyword">for</span> <span class="hljs-built_in">j</span> = <span class="hljs-number">1</span>:<span class="hljs-built_in">size</span>(model.X, <span class="hljs-number">1</span>)  
            prediction = prediction + ...  
                model.alphas(<span class="hljs-built_in">j</span>) * model.y(<span class="hljs-built_in">j</span>) * ...  
                model.kernelFunction(X(<span class="hljs-built_in">i</span>,:)&apos;, model.X(<span class="hljs-built_in">j</span>,:)&apos;);  
        <span class="hljs-keyword">end</span>  
        p(<span class="hljs-built_in">i</span>) = prediction + model.b;  
    <span class="hljs-keyword">end</span>  
<span class="hljs-keyword">end</span>  

<span class="hljs-comment">% Convert predictions into 0 / 1  </span>
pred(p &gt;= <span class="hljs-number">0</span>) =  <span class="hljs-number">1</span>;  
pred(p &lt;  <span class="hljs-number">0</span>) =  <span class="hljs-number">0</span>;  

<span class="hljs-keyword">end</span>
</code></pre>
<h2 id="part-4-test-spam-classification">Part 4: Test Spam Classification</h2>
<hr>
<p>training example&#xC5D0;&#xC11C; &#xD559;&#xC2B5;&#xD55C; &#xBAA8;&#xB378;&#xC744; &#xAC00;&#xC9C0;&#xACE0; test set&#xC5D0;&#xC11C;&#xB3C4; &#xC801;&#xC911;&#xD558;&#xB294;&#xC9C0; &#xB9DE;&#xCDB0;&#xBCF8;&#xB2E4;.   </p>
<pre><code class="lang-matlab">p = svmPredict(model, Xtest);  
fprintf(<span class="hljs-string">&apos;Test Accuracy: %f\n&apos;</span>, mean(double(p == ytest)) * <span class="hljs-number">100</span>);
</code></pre>
<h2 id="part-5-top-predictors-of-spam">Part 5: Top Predictors of Spam</h2>
<hr>
<p>Spam&#xC73C;&#xB85C; &#xBD84;&#xB958;&#xB418;&#xB294;&#xB370; &#xAC00;&#xC7A5; &#xB9CE;&#xC740; weight&#xB97C; &#xAC16;&#xB294; &#xB2E8;&#xC5B4; 10&#xAC1C;&#xB97C; &#xC21C;&#xC11C;&#xB300;&#xB85C; &#xBCF4;&#xC5EC;&#xC900;&#xB2E4;.   </p>
<pre><code class="lang-matlab"><span class="hljs-comment">% Sort the weights and obtin the vocabulary list  </span>
[weight, idx] = sort(model.w, <span class="hljs-string">&apos;descend&apos;</span>);  
vocabList = getVocabList();  

fprintf(<span class="hljs-string">&apos;\nTop predictors of spam: \n&apos;</span>);  
<span class="hljs-keyword">for</span> <span class="hljs-built_in">i</span> = <span class="hljs-number">1</span>:<span class="hljs-number">15</span>  
    fprintf(<span class="hljs-string">&apos; %-15s (%f) \n&apos;</span>, vocabList{idx(i)}, weight(<span class="hljs-built_in">i</span>));  
<span class="hljs-keyword">end</span>
</code></pre>
<h2 id="part-6-try-your-own-emails">Part 6: Try Your Own Emails</h2>
<hr>
<p>&#xAE30;&#xC874;&#xC5D0; train&#xD55C; model&#xC744; &#xAC00;&#xC9C0;&#xACE0;, &#xC2E0;&#xADDC; &#xBA54;&#xC77C; emailSample4.txt &#xC774; spam &#xC778;&#xC9C0; &#xC544;&#xB2CC;&#xC9C0; &#xC608;&#xCE21;&#xD558;&#xAE30;!  </p>
<pre><code class="lang-matlab">filename = <span class="hljs-string">&apos;emailSample4.txt&apos;</span>;  

<span class="hljs-comment">% Read and predict  </span>
file_contents = readFile(filename);  
word_indices  = processEmail(file_contents);  
x             = emailFeatures(word_indices);  
p = svmPredict(model, x);  

fprintf(<span class="hljs-string">&apos;\nProcessed %s\n\nSpam Classification: %d\n&apos;</span>, filename, p);
</code></pre>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="ex6-1-support-vector-machines.html" class="navigation navigation-prev " aria-label="Previous page: ex6 1 Support vector machines">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="ex7-k-means-clustering-and-pca.html" class="navigation navigation-next " aria-label="Next page: ex7 K-means clustering and pca">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"ex6 2 Spam classification","level":"3.9","depth":1,"next":{"title":"ex7 K-means clustering and pca","level":"3.10","depth":1,"path":"markdowns/ex7-k-means-clustering-and-pca.md","ref":"markdowns/ex7-k-means-clustering-and-pca.md","articles":[]},"previous":{"title":"ex6 1 Support vector machines","level":"3.8","depth":1,"path":"markdowns/ex6-1-support-vector-machines.md","ref":"markdowns/ex6-1-support-vector-machines.md","articles":[]},"dir":"ltr"},"config":{"gitbook":"*","theme":"default","variables":{"BASE_URL":"http://soopsaram.com/platform_dd/"},"plugins":["ga","mathjax","theme-darkblue","simple-page-toc","disqus","back-to-top-button","edit-link","github"],"pluginsConfig":{"disqus":{"useIdentifier":false,"shortName":"jihuun"},"github":{"url":"https://github.com/jihuun/ml"},"simple-page-toc":{"maxDepth":2,"skipFirstH1":true},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-darkblue":{},"highlight":{},"back-to-top-button":{},"mathjax":{"forceSVG":false,"version":"2.6-latest"},"ga":{"configuration":"auto","token":"UA-145404461-1"},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"edit-link":{"label":"Edit","base":"https://github.com/jihuun/ml/edit/master"},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"}},"file":{"path":"markdowns/ex6-2-spam-classification.md","mtime":"2019-08-29T11:14:14.344Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2019-08-29T11:15:02.506Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="../gitbook/gitbook-plugin-ga/plugin.js"></script>
        
    
        
        <script src="https://cdn.mathjax.org/mathjax/2.6-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-mathjax/plugin.js"></script>
        
    
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/URI.js/1.16.1/URI.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-disqus/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-back-to-top-button/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-edit-link/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-github/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

